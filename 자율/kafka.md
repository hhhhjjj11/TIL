# 강의내용 정리
## 카프카
- 카프카 = 메시지큐잉서버

### 카프카란?
- 메시지브로커 : 특정 리소스에서 다른 리소스로 메시지를 전달할때 사용되는 서버
    - 즉, 메시지를 전달하는 서버
- 전산에서 보내는 메시지란 여러형태를 가질 수 있는데, JSON / XML / 자바가가지는 Object등이 있음.
- 레빗엠큐와 카프카 둘 다 같은 기능을 할 수 있지만, 대용량 처리시 안정성 측면에서 카프카가 우위에있음.
- end to end 방식의 어려움 -> 대안으로서 카프카의 효용 부각
   - end to end 란 서로 연결된 리소스 양 끝단 끼리 직접 통신 
   - 각각의 양 끝(메시지를 받는쪽과 보내는 쪽)을 연결하는 pipeline이 많아야함
   - resource들이 많아질 수록 확장이 매우 어려움
- 카프카를 도입하면 받는쪽과 보내는 쪽을 일일이 연결하지 않고, 중간에 카프카를 둠으로써 편리하게 처리 가능
- 메시지를 보내는 쪽인 프로듀서와 받는 쪽인 컨슈머를 분리하여 작업할 수 있게 됨

### 카프카 브로커
- 실행된 카프카 애플리케이션 서버를 칭함
- 일반적으로는 카프카 브로커를 세 대이상 동시에 돌리는 것(클러스터링 구성)을 권장함
- 하나가 터져도 나머지로 돌릴 수 있도록
- 그러면 그런 관리(카프카 하나가 터졌을 때 나머지가 터진애역할까지 하게 하는 등의 장애관리)는 누가하냐?
- 그걸 해주는 애를 "코디네이터 시스템"이라고 하고 카프카의 코디네이터 시스템은 일반적으로 아파치의 주키퍼가 사용됨.
 
### 주키퍼
- 일반적으로 권장되는 여러대의 브로커를 컨트롤 해주는 코디네이터 시스템.
- 일반적으로 여러대의 브로커를 돌릴 때 한 개는 컨트롤러 역할을 하는 브로커로 사용함.

### 카프카설치하기
- http://kafka.apache.org/
- 스칼라 2.12로 만들어진 버전과 스칼라 2.13로 만들어진 버전이 있다. (스칼라는 프로그래밍 언어 이름이다.)
- 이 중 2.13 언어로 만들어진 것을 선택 (강의에서는 2.70버전을 이용하였다.) 
- 카프카는 OS별로 파일을 분기하여 제공하지 않고 하나의 파일을 받으면 그 안에 윈도우 명령어와 매OS 커맨드가
같이 들어있는 식이다.

- 설치한 후 압축을 해제해주자 
   - 이 때, cmd에서 cli 명령어 tar xvf 를 이용해 압축을 풀 수도 있다.
   - (참고로 위 tar 명령어는 맥OS 명령어이나, 윈도우10부터는 윈도우에서도 지원하는 명령어이다.)

### 카프카 폴더 구조 살펴보기
1. bin : 각종 실행 커맨드가 들어있는 폴더
- 기본적으로 .sh파일이 있고 windows 폴더가 있음
- windows 폴더 안에는 bat파일 들이 있음
2. config : 각종 설정 파일
  

### 카프카 사용 시나리오  (에코시스템, 즉 생태계라고 나타내는 듯)
- 시나리오1 [Kafka-client]: 카프카에 메시지를 보내고, 그 메시지를 카프카가 다른 컨슈머에게 전달하는 시나리오
- 시나리오2 [Kafka-connect]: DB변동사항 발생 시 카프카가 해당 내용을 캐치하여 메시지를 만들어내고 그 값을 다른 DB등의 리소스에 전달해주는 시나리오

### 카프카 클라이언트 
방법1: 카프카와 데이터를 주고받기 위해 사용되는 자바라이브러리"kafka-client"를 이용한 방법
- 참고: cwiki.apache.org/confluence/display/KAFKA/Clients 들어가면 카프카 라이브러리를 사용가능한 프로그래밍 언어를 확인 가능

## 테스트해보기
### 자바를 통해 구현하기 전에 샘플 프로그램을 통해 카프카의 동작 방식 및 원리 테스트 해보자
- 카프카를 설치하면 프로듀서하고 컨슈머를 간단하게 터미널 상으로 테스트할 수 있는 샘플 프로그램을 제공해준다.
그  샘플 프로그램을 이용해서 메시지를 주고받아보자.  
1. 주키퍼 서버 기동 (설정파일 지정도 함께 해준다.)
```
$ .\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties
```
2. 카프카 서버 기동(default port = 9092) -> 설정파일 지정 (주키퍼가 먼저 기동 되어야 한다)
```
$ KAFKA_HOME\bin\windows\kafka-server-start.bat KAFKA_HOME\config\server.properties
```

- note. 프로듀서에서 메시지를 보내면 그 데이터는 topic이라는 곳에 저장이 된다.
- note. 토픽은 임의로 자유롭게 만들어낼 수 있다.
- note. 흐름: 토픽을 만들고 -> 토픽에 프로듀서가 메시지를 보냄 -> 컨슈머는 특정 토픽을 구독함, 해당 토픽에 이벤트 발생시 컨슈머에게 메시지 전달.
- note. 의의: 보내는 쪽과 받는 쪽은 서로 양끝단을 신경쓸 필요가 없음 (end-to-end와 비교)

3. 토픽생성
```
$ KAFKA_HOME/bin/windows/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic quickstart-events --partitions 1
```
- quickstart-event라는 이름의 토픽을 로컬호스트 9092포트 서버에 생성하겠다.
- note. 9092는 카프카의 디폴트 포트넘버.
- partition1 -> 멀티 클러스터링 할때에 몇군데에 토픽을 만들것인지 설정하는 건데 테스트에서는 카프카를 한대만 쓸 것이므로 1로 지정.

note. 토픽 목록 확인
```
$ KAFKA_HOME/bin/windows/kafka-topic.sh --bootstrap-server localhost:9092 --list
```
note. 토픽 정보 확인
```
$ KAFKA_HOME/bin/windows/kafka-topic.sh --describe --topic quickstart-events --bootstrap-server localhost:9092
```

### 메시지 만들기
- cli 명령어를 통해 간단히 프로듀서와 컨슈머를 기동 시킬 수 있음.
```
$ ./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic quickstart-events 
// 카프카 서버 지정 , 토픽 이름 지정
```
- 실행하게 되면 프롬프트가 나온다. 거기에 메시지를 입력하면 됨.
- 컨슈머를 기동해보자
```
$ ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic quickstart-events --from-beginning
// from beginning : 처음 메시지부터 다나오도록 함. 
```

### 트러블 슈팅
- 윈도우에서 주키퍼 서버 기동하려할 때 명령어가 너무 길어서 실행할 수 없다고 나옴.
- batch파일을 편집하여 해결함. 아래 링크 참조
- https://kimdeveloper.tistory.com/28

### 토픽이 안만들어짐 
- 에러뜸.. 넘어감.. 나중에 해결해보기
-------------------------------


### 두번째시나리오: 카프카 커넥트
- 데이터를 자유롭게 주고받을 수있도록 하는 기능
- RESTful API를 통해 지원하기 때문에 포스트맨 등으로 테스트가 가능함. 커넥트 CRUD 등 등
- 카프카 커넥트 소스와 카프카 커넥트 싱크
    - 카프카 커넥트 소스 : 데이터가 저장되어 있는 곳 DB등
    - 카프카 커넥트 싱크 : 카프카 클러스터(브로커들의 모임을 말하는듯)에 저장된 데이터 값을 내보내 주는 역할
- 흐름: 커넥터에 소스커넥터 등록(db정보 토픽정보 ..) , db에서 데이터 변화 -> 토픽에 해당 내용을 반영한 데이터가 쌓임
-> 커넥터에 싱크커넥터등록(토피정보) (싱크커넥터 : 토픽에 저장된 데이터를 가지고와서 사용)  -> 
note.싱크커넥터는 연결된 테이블을 가진다. 이때 이 테이블은 토픽과 같다..(?)
-> 토픽에 데이터가 업데이트 됨과 동시에 싱크커넥터에 연결된 테이블에 동일하게 반영해주고 

흐름.
1. 카프카 프로듀서를 이용해서 데이터 전송
  - 이 때 쿼리가 아니라 토픽에서 사용할 수 있는 메시지 포맷으로 데이터를 전송한다.
2. 그러면 토픽에 데이터가 추가된다.
3. 즉, 싱크커넥터가 업데이트 되어있는 토픽의 데이터를 가져와서 자신이 연결된 테이블에도 반영해줌



 
### 카프카 커넥트 설치하기 (이 부분은 정리가 제대로 안됨. 강의 참조할 것)
1. 카프카 커넥트설치
- windows (mac은 강의 참고)
```
$ curl -O http://packages/confluent.io/archive/6.1/confluent-community-6.1.0.tar.gz
$ tar xvf confluent-community-6.1.0.tar.gz
$ cd KAFKA_CONNECT_HOME
```
- Classpath is empty 에러발생시 -> 강의 참고 (9분20초)
 
2. connect-distributed.properties 파일에 JDBC 설정 코드 한 줄 추가 해준다.
- 관계형 데이어베이스를 이용할건데, 자바에서 관계형 db를 사용하려면 JDBC라는 라이브러리를 이용해줘야함
- jdbc 를 다운로드 해주고,
```
plugin.path= ~\\confluentinc-kafka-connect-jdbc-10.0.1\\lib
```
- 마리아DB를 사용하기 위해 mariadb 드라이버 복사해준다.. (강의참고)

### 커넥트 사용해보기 
- 마찬가지로, 샘플 프로그램을 이용
- 우선, 주키퍼와 카프카 클라이언트가 기동된 상태에서 진행해주어야 한다. (유레카도 켜야하는지는 모르겠다.)
- 카프카 소스 커넥터 추가 
   - 커넥터 기동한 서버로 post 요청을 보내면됨.

- 싱크커넥트 추가
  -> 정상적으로 싱크커넥트가 만들어짐 ->  토픽의 이름과 같은 형태의테이블이 만들어졌음을 의미



다시정리.
소스커넥터는 db의 변동을 감지하여 토픽에 저장해주는 역할
싱크커넥터는 토픽의 변동을 db에 반영해주는 역할
이때 소스커넥터에 db1을 등록하고 싱크커넥터에 db2를 등록하면
db1과 db2가 연동되게 되는거임.

- 참고 ETL 데이터이관기술 Extract Transform Load 카프카의 커넥터를 이용해서 가능하게됨.


- 프로듀서는 아무런 텍스트나 보낼 수 있지만, 싱크커넥트가 동작하기위한 jdbc포맷을 맞춰 보내야만 알맞게 동작한다.
(해당 포맷 중에서 payload 키가 실제로 db에 반영되는 데이터 내용이다.)

# 우리서버에 카프카 적용하기
코드 작성 흐름
- 컨슈머가 토픽을 구독하도록 하고 나서 프로듀서로직을 작성하는것을 추천

## 우선, 컨슈머 서버 로직 작성
1. 의존성추가, spring-kafka
2. KafkaConsumerConfig: Configuration 로직 작성
   1. ConsumerFactory: 토픽에 접속하기 위한 설정을 포함하는 로직
      - 카프카 서버의 주소 입력
      - Deserializer 설정로직
   2. ConcurrentKafkaListenerContainerFactory: 토픽의 변경사항을 감지하도록 하는 리스터를 등록하는 로직

note. 토픽에 저장 되는 데이터 형태는 JSON 형식이고 직렬화를 거쳐 key, value가 한 세트로 저장되어 있음
그것을 가지고 와서 역으로 해석을 해서 사용을 해야함. 이때 해석하는 과정을 Deserializer 라고 함

note.
Serializer: 데이터를 전달하기 위해 압축하는 과정을 수행하는 객체
Deserializer: 데이터를 받아서 압축을 해제하는 과정을 수행하는 객체

3. KafkaConsumer 로직 작성 (@Service)
  - repository를 호출하여 사용하는 서비스로직임
  - 실제 데이터에 반영해주는 작업 수행
  3.1 processMessage: @KafkaListener를 이용하여 토픽을 지정하고 이벤트리스너 함수 작성
      - 

```
예시) 주문 -> 주문 수량 만큼 재고db에서 감소 시켜주어야 함
카프카 컨슈머의 order-topic 리스너에서 메시지를 인자로받고.
메시지를 가지고 데이터를 읽어내고 (TypeReference?)
JPA, 레파지토리 로직을 가지고 update한 후 repository.save(entity) 해줌.
```

### 프로듀서 서버 로직 작성
1. spring-kafka 의존성 추가
2. KafkaProducerConfig: Configuration 로직 작성
  1. ProducerFactory
    - 사용하는 카프카 서버 주소
    - 시리얼라이저 설정 코드
  2. KafkaTemplate
    - 토픽에 데이터를 보내기 위해 필요한 객체
3. KafkaProducer 로직 작성(@Service)
  - kafkaTemplate을 이용한다.
  - send 메서드 
    - 토픽이름과 dataDto를 인자로 받고
    - 매퍼를 이용해서 dataDto를 JSON으로 변환 
    - 그 후 kafkaTemplate.send(topic, json) 으로 송출

--------------------------------------
<br><br>
### 다른 메모...

1. 케이스생각
2. 프로듀서와 컨슈머 생각

case1: 회원탈퇴시 관련 데이터 삭제
case2: 관측포인트가 삭제될일은 없으니.. 넘어가.


======================================
<Case1>
프로듀서 : Member Service

컨슈머 :
1. StarCard Service O
  - 천체카드 삭제 (탈퇴회원이 작성한 카드)  // Cascade설정 걸려서 관계된 좋아요 데이터 다 삭제되는지 확인
  - 천체카드 좋아요 삭제 (탈퇴회원이 다른 사람이 만든 카드 좋아요한 내용 삭제)
2. 채팅 
  - 채팅방 참여 삭제
  - 채팅 메시지 삭제  // 몽고디비라 후순위로 밀고
3. 관측포인트
  - 관측포인트리뷰삭제

결과 -> 후순위 하나 빼고 
1. 천체카드 삭제, 
2. 천체카드좋아요삭제, 
3. 채팅방참여삭제, 
4. 관측포인트리뷰삭제.
======================================


이제 해야할 일 순서대로 정리.

주키퍼랑 카프카 띄우고.
코드작성

# 트러블 슈팅
### FK가아닌 연결 -> 따로 지워줘야 됨
카프카에서 memberId에 해당하는 Starcard를 삭제했을때 => 카드id를 FK로 가지는 cardLike은 지워져도. (연관관계)
지워진 카드에 연관되지 않으면 안지워짐. 즉, memberId 에 해당해도 cardLike 이 안지워질 수 있음. 
따라서 따로 지우는 과정이 필요함


### 파티션과 컨슈머, 컨슈머그룹
1. 하나의 토픽에는 여러개의 파티션이 있다.
2. 컨슈머그룹에는 여러개의 컨슈머 인스턴스가 들어있다.
3. 하나의 파티션은 컨슈머그룹별로 전달 가능하다.
4. 하지만 컨슈머그룹안에서는 하나의 컨슈머인스턴스에만 연결된다.
5. 일반적으로 컨슈머 그룹은 동일한 서버를 동시에 여러개 돌릴때 묶는듯하다.
6. 따라서 서로 다른 서버는 서로다른 컨슈머그룹에 속하게한다. 
같은 컨슈머그룹에 속하면 하나에서만 메시지를 받을 수 있다. 나머지에는 연락안감.
7. 컨슈머그룹id를 다르게 지정하여 컨슈머그룹을 구분하면 해결된다.
